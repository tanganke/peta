{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, List\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hydra\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "import peft\n",
    "import torch\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, default_data_collator\n",
    "\n",
    "import peta\n",
    "from peta.models.LinearizedModel import LinearizedModelWraper\n",
    "from peta.utils import TimeIt, TitledLog\n",
    "from peta.utils.logging.rich import pprint_yaml, setup_colorlogging\n",
    "from peta.utils.ml.devices import num_devices\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# disable tokenizers parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from finetune_lm import load_model_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    }
   ],
   "source": [
    "fabric = L.Fabric(accelerator=\"cuda\", devices=[0])\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(\n",
    "    model: str,\n",
    "    dataset: str,\n",
    "    finetune_mode: str,\n",
    "    version: int,\n",
    "):\n",
    "    log_dir: Path = (\n",
    "        Path(\"logs\") / model / dataset / finetune_mode / f\"version_{version}\"\n",
    "    )\n",
    "    config_path = log_dir / \"config.yaml\"\n",
    "    cfg: DictConfig = OmegaConf.load(config_path)\n",
    "\n",
    "    # load model from config\n",
    "    with TitledLog(\"load pretrained model and tokenizer\", log_fn=log.info):\n",
    "        _return = load_model_from_config(cfg)\n",
    "        tokenizer: AutoTokenizer = _return[\"tokenizer\"]\n",
    "        model: AutoModelForSeq2SeqLM | peft.PeftModel = _return[\"model\"]\n",
    "        model.eval()\n",
    "\n",
    "    return {\n",
    "        \"config\": cfg,\n",
    "        \"model\": model,\n",
    "        \"tokenizer\": tokenizer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetuned_model(\n",
    "    model: str,\n",
    "    dataset: str,\n",
    "    finetune_mode: str,\n",
    "    version: int,\n",
    "):\n",
    "    log_dir: Path = (\n",
    "        Path(\"logs\") / model / dataset / finetune_mode / f\"version_{version}\"\n",
    "    )\n",
    "    config_path = log_dir / \"config.yaml\"\n",
    "    cfg: DictConfig = OmegaConf.load(config_path)\n",
    "\n",
    "    # load model from config\n",
    "    with TitledLog(\"load pretrained model and tokenizer\", log_fn=log.info):\n",
    "        _return = load_model_from_config(cfg)\n",
    "        tokenizer: AutoTokenizer = _return[\"tokenizer\"]\n",
    "        model: AutoModelForSeq2SeqLM | peft.PeftModel = _return[\"model\"]\n",
    "\n",
    "        # load checkpoint\n",
    "        checkpoint_dir = log_dir / \"checkpoints\"\n",
    "        checkpoints = os.listdir(checkpoint_dir)\n",
    "        # get checkpoint files with `step=2000.pth` in its name\n",
    "        checkpoints = list(filter(lambda x: \"step=2000.pth\" in x, checkpoints))\n",
    "        # assert (\n",
    "        #     len(checkpoints) == 1\n",
    "        # ), f\"multiple checkpoints found, found checkpoints: {checkpoints}, checkpoint dir: {checkpoint_dir}\"\n",
    "        assert (\n",
    "            len(checkpoints) >= 1\n",
    "        ), f\"no checkpoint found, checkpoint dir: {checkpoint_dir}\"\n",
    "        if len(checkpoints) > 1:\n",
    "            log.warn(\n",
    "                f\"multiple checkpoints found, found checkpoints: {checkpoints}, checkpoint dir: {checkpoint_dir}\"\n",
    "            )\n",
    "        checkpoint = checkpoints[0]\n",
    "        log.info(f\"load checkpoint from {checkpoint}\")\n",
    "\n",
    "        # load trainable parameters\n",
    "        state_dict = torch.load(checkpoint_dir / checkpoint, map_location=\"cpu\")\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.eval()\n",
    "\n",
    "    return {\n",
    "        \"config\": cfg,\n",
    "        \"model\": model,\n",
    "        \"tokenizer\": tokenizer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:39:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1323327/501775352.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501775352.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/501775352.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:39:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=825329;file:///tmp/ipykernel_1323327/501775352.py\u001b\\\u001b[2m501775352.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=581389;file:///tmp/ipykernel_1323327/501775352.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:39:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:39:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=538520;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=932733;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">3_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1323327/501775352.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501775352.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/501775352.py#28\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m3_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=890846;file:///tmp/ipykernel_1323327/501775352.py\u001b\\\u001b[2m501775352.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=21436;file:///tmp/ipykernel_1323327/501775352.py#28\u001b\\\u001b[2m28\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1323327/501775352.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501775352.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/501775352.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=322444;file:///tmp/ipykernel_1323327/501775352.py\u001b\\\u001b[2m501775352.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=371554;file:///tmp/ipykernel_1323327/501775352.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"flan-t5-base\"\n",
    "dataset = \"glue-cola\"\n",
    "finetune_mode = \"standard\"\n",
    "\n",
    "model = load_finetuned_model(model, dataset, finetune_mode, 0)\n",
    "cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "datasets = instantiate(cfg.dataset.datasets)\n",
    "\n",
    "if \"validation\" in datasets:\n",
    "    val_dataset = datasets[\"validation\"]\n",
    "elif \"validation_matched\" in datasets:\n",
    "    # mnli\n",
    "    val_dataset = datasets[\"validataion_matched\"]\n",
    "else:\n",
    "    raise KeyError(datasets.keys())\n",
    "\n",
    "# convert the task to text-to-text format\n",
    "if hasattr(cfg.dataset, \"preprocessor\"):\n",
    "    preprocessor = instantiate(\n",
    "        cfg.dataset.preprocessor,\n",
    "        tokenizer=tokenizer,\n",
    "        tokenizer_kwargs=cfg.model.tokenizer_kwargs\n",
    "        if hasattr(cfg.model, \"tokenizer_kwargs\")\n",
    "        else None,\n",
    "    )\n",
    "    val_dataset = val_dataset.map(\n",
    "        preprocessor,\n",
    "        **cfg.dataset.map_kwargs if hasattr(cfg.dataset, \"map_kwargs\") else {},\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    collate_fn=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    }
   ],
   "source": [
    "model = fabric.setup_module(model)\n",
    "val_loader = fabric.setup_dataloaders(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_tokens(tokenizer, token_list):\n",
    "    ret = []\n",
    "    for token in token_list:\n",
    "        if token not in tokenizer.all_special_ids and token > 0:\n",
    "            ret.append(token)\n",
    "        if token == -100:\n",
    "            break\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, val_loader: DataLoader, tokenizer):\n",
    "    from tqdm import tqdm\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model = model.eval()\n",
    "    for batch_idx, batch in enumerate(tqdm(val_loader)):\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(batch[\"input_ids\"])\n",
    "            output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "            labels = [remove_special_tokens(tokenizer, l) for l in batch[\"labels\"]]\n",
    "            labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # compare output_text and labels\n",
    "            for i, j in zip(output_text, labels):\n",
    "                if i == j:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    # return accuracy\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/131 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 131/131 [00:19<00:00,  6.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6951102588686481"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(model, val_loader, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroShot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model_and_dataset(\n",
    "    model: str, dataset: str, finetune_mode: str = \"standard\", version: int = 0\n",
    "):\n",
    "    model = load_pretrained_model(\n",
    "        model,\n",
    "        dataset,\n",
    "        finetune_mode=finetune_mode,\n",
    "        version=version,\n",
    "    )\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    datasets = instantiate(cfg.dataset.datasets)\n",
    "\n",
    "    if \"validation\" in datasets:\n",
    "        val_dataset = datasets[\"validation\"]\n",
    "    elif \"validation_matched\" in datasets:\n",
    "        # mnli\n",
    "        val_dataset = datasets[\"validation_matched\"]\n",
    "    else:\n",
    "        raise KeyError(datasets.keys())\n",
    "\n",
    "    # convert the task to text-to-text format\n",
    "    if hasattr(cfg.dataset, \"preprocessor\"):\n",
    "        preprocessor = instantiate(\n",
    "            cfg.dataset.preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            tokenizer_kwargs=cfg.model.tokenizer_kwargs\n",
    "            if hasattr(cfg.model, \"tokenizer_kwargs\")\n",
    "            else None,\n",
    "        )\n",
    "        val_dataset = val_dataset.map(\n",
    "            preprocessor,\n",
    "            **cfg.dataset.map_kwargs if hasattr(cfg.dataset, \"map_kwargs\") else {},\n",
    "        )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        collate_fn=default_data_collator,\n",
    "    )\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "\n",
    "    return model, tokenizer, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:39:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:39:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=683304;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=623505;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:39:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:39:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=411825;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234863;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=124672;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=335831;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 33/33 [00:25<00:00,  1.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:39:49] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:39:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=987109;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=571087;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:39:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:39:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=783262;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=114612;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=700047;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=176577;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee79c07513c43d6b6c2352db15961c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [04:02<00:00,  1.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=570047;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=58741;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=893413;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=655474;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=553242;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=880126;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c3804ccd734bddafb2c4e9646fe699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:10<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=403992;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=938523;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:44:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:44:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=535570;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=726905;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=414641;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=58330;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fc0f7f6b884f94baca87de5dc5a27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/40430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [19:44<00:00,  1.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:04:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:04:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=915700;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=113627;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:04:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:04:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=53839;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=902448;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=592107;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=583831;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cfbd1b8fa04dada023cec5b136b51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:08<00:00,  1.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:04:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:04:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=193222;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=5710;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:04:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:04:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=132687;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=492897;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=825679;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=469383;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:04:57] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:04:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=648720;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=575852;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d76279c98f0429d82be027aa007041f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:20<00:00,  1.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:05:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:05:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                             \u001b]8;id=651460;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=568811;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:05:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:05:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=478522;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=532869;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                             <a href=\"file:///tmp/ipykernel_1323327/2329344656.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2329344656.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1323327/2329344656.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                             \u001b]8;id=745175;file:///tmp/ipykernel_1323327/2329344656.py\u001b\\\u001b[2m2329344656.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=836771;file:///tmp/ipykernel_1323327/2329344656.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2059c3dd1f4e4b7eae82a805526ddbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:38<00:00,  1.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy\n",
       "0  flan-t5-base  glue-cola       0.0\n",
       "1  flan-t5-base  glue-mnli       0.0\n",
       "2  flan-t5-base  glue-mrpc       0.0\n",
       "3  flan-t5-base   glue-qqp       0.0\n",
       "4  flan-t5-base   glue-rte       0.0\n",
       "5  flan-t5-base  glue-sst2       0.0\n",
       "6  flan-t5-base  glue-stsb       0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_results = {\"model\": [], \"dataset\": [], \"accuracy\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model, tokenizer, val_loader = load_pretrained_model_and_dataset(\n",
    "        model_name, dataset_name, \"standard\", 0\n",
    "    )\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    zeroshot_results[\"model\"].append(model_name)\n",
    "    zeroshot_results[\"dataset\"].append(dataset_name)\n",
    "    zeroshot_results[\"accuracy\"].append(acc)\n",
    "\n",
    "zeroshot_results = pd.DataFrame(zeroshot_results)\n",
    "zeroshot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full-Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_dataloaer(cfg: DictConfig, batch_size=32):\n",
    "    datasets = instantiate(cfg.dataset.datasets)\n",
    "\n",
    "    if \"validation\" in datasets:\n",
    "        val_dataset = datasets[\"validation\"]\n",
    "    elif \"validation_matched\" in datasets:\n",
    "        # mnli\n",
    "        val_dataset = datasets[\"validation_matched\"]\n",
    "    else:\n",
    "        raise KeyError(datasets.keys())\n",
    "\n",
    "    # convert the task to text-to-text format\n",
    "    if hasattr(cfg.dataset, \"preprocessor\"):\n",
    "        preprocessor = instantiate(\n",
    "            cfg.dataset.preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            tokenizer_kwargs=cfg.model.tokenizer_kwargs\n",
    "            if hasattr(cfg.model, \"tokenizer_kwargs\")\n",
    "            else None,\n",
    "        )\n",
    "        val_dataset = val_dataset.map(\n",
    "            preprocessor,\n",
    "            **cfg.dataset.map_kwargs if hasattr(cfg.dataset, \"map_kwargs\") else {},\n",
    "        )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "        collate_fn=default_data_collator,\n",
    "    )\n",
    "\n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validataion_dataloaders = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:17:08] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:17:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=414858;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=550654;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:17:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:17:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=341932;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=701077;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">3_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m3_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=647399;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=848280;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=92983;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=632879;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [06:00<00:00, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.6951102588686481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:23:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:23:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=982399;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=279421;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:23:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:23:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=994356;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=443532;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=93871;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210982;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:23:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:23:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=697494;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=944990;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:23:35] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:23:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=350934;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=857444;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [15:44<00:00,  3.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.8141619969434539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=342476;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=519518;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=699765;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=821631;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757684/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/standard/version_0/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=12521;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776510;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/standard/version_0/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=80264;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703954;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=955674;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=145182;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:27] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=830468;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=815071;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.8235294117647058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=315021;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=590946;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:40] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=260128;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631389;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/standard/version_0/checkpoints                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=682805;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=90985;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/standard/version_0/checkpoints                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=674874;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826350;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=706552;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=845949;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:39:43] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:39:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=921671;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256794;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [15:30<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.8293346524857779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:14] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=116464;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=129401;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=745989;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=382425;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/standard/version_0/checkpoints                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=678604;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=673981;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/standard/version_0/checkpoints                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=276155;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=948384;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=887815;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=371687;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:20] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=106252;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=441681;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:07<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.851985559566787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=225298;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=274172;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=669528;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=247654;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-sst2/standard/version_0/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=973809;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=555781;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-sst2/standard/version_0/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=997279;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=806159;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=290288;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=15871;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:33] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=206664;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=616196;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:13<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-sst2, accuracy: 0.9334862385321101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=979834;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=222978;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=966242;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803511;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=5_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=6_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-stsb/standard/version_0/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m5_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=934678;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104432;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-stsb/standard/version_0/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">5_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m5_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=577984;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=569707;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:55:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:55:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=581784;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=287369;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:28<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-stsb, accuracy: 0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.695110</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.814162</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.829335</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.933486</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.695110   \n",
       "1  flan-t5-base  glue-mnli  0.814162   \n",
       "2  flan-t5-base  glue-mrpc  0.823529   \n",
       "3  flan-t5-base   glue-qqp  0.829335   \n",
       "4  flan-t5-base   glue-rte  0.851986   \n",
       "5  flan-t5-base  glue-sst2  0.933486   \n",
       "6  flan-t5-base  glue-stsb  0.196000   \n",
       "\n",
       "                                              config  \n",
       "0  [model, peft, dataset, optim, seed, batch_size...  \n",
       "1  [model, peft, dataset, optim, seed, batch_size...  \n",
       "2  [model, peft, dataset, optim, seed, batch_size...  \n",
       "3  [model, peft, dataset, optim, seed, batch_size...  \n",
       "4  [model, peft, dataset, optim, seed, batch_size...  \n",
       "5  [model, peft, dataset, optim, seed, batch_size...  \n",
       "6  [model, peft, dataset, optim, seed, batch_size...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullfinetuned_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "finetune_mode = \"standard\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model = load_finetuned_model(model_name, dataset_name, finetune_mode, 0)\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    if dataset_name in validataion_dataloaders:\n",
    "        val_loader = validataion_dataloaders[dataset_name]\n",
    "    else:\n",
    "        val_loader = load_validation_dataloaer(cfg)\n",
    "        validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    fullfinetuned_results[\"model\"].append(model_name)\n",
    "    fullfinetuned_results[\"dataset\"].append(dataset_name)\n",
    "    fullfinetuned_results[\"accuracy\"].append(acc)\n",
    "    fullfinetuned_results[\"config\"].append(cfg)\n",
    "\n",
    "    print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "fullfinetuned_results = pd.DataFrame(fullfinetuned_results)\n",
    "fullfinetuned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "fullfinetuned_results.to_csv(f\"results/{model_name}/fullfinetuned_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:36:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:36:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:36:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:36:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757684/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=4_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=3_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-cola/standard/version_1/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=617889;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291704;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m3_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-cola/standard/version_1/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m4_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=844962;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=167414;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:36:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:36:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=163032;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225772;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [00:16<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.7526366251198466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:36:49] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:36:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=398382;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=101414;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:36:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:36:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=277370;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=846335;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=130889;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=967096;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:36:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:36:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=869693;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=659176;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [03:09<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.8241467142129394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:40:01] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:40:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=605397;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=201629;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:40:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:40:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=238968;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=810620;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/standard/version_1/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=908573;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=105907;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/standard/version_1/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=874628;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=382554;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:40:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:40:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=702729;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=279946;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.8578431372549019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:40:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:40:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=74870;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=638720;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:40:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:40:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=256702;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=171339;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/standard/version_1/checkpoints                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=671088;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=721590;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/standard/version_1/checkpoints                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=883794;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=805635;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:40:26] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:40:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=33659;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=844151;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [15:09<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.8360870640613406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:55:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:55:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=221231;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=957492;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:55:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:55:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=329963;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=222955;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/standard/version_1/checkpoints                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=958972;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=674079;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/standard/version_1/checkpoints                       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=258607;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=781177;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:55:40] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:55:40]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=612982;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=449245;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.851985559566787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:55:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:55:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=229974;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=145051;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:55:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:55:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=49405;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=902931;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-sst2/standard/version_1/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=830555;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=713536;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-sst2/standard/version_1/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=400156;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=624834;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:55:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:55:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=902592;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=988210;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:13<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-sst2, accuracy: 0.9334862385321101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:56:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:56:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=714825;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=927767;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:56:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> no peft config found, use full finetuning.                                   <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:56:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m no peft config found, use full finetuning.                                   \u001b]8;id=672097;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=356699;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#128\u001b\\\u001b[2m128\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=5_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=6_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-stsb/standard/version_1/checkpoints                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m5_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=475763;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=3402;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-stsb/standard/version_1/checkpoints                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">5_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m5_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=524902;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=798975;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:56:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:56:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=912804;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=655674;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:27<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-stsb, accuracy: 0.19866666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.752637</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.824147</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.836087</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.851986</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.933486</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.198667</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.752637   \n",
       "1  flan-t5-base  glue-mnli  0.824147   \n",
       "2  flan-t5-base  glue-mrpc  0.857843   \n",
       "3  flan-t5-base   glue-qqp  0.836087   \n",
       "4  flan-t5-base   glue-rte  0.851986   \n",
       "5  flan-t5-base  glue-sst2  0.933486   \n",
       "6  flan-t5-base  glue-stsb  0.198667   \n",
       "\n",
       "                                              config  \n",
       "0  [model, peft, dataset, optim, seed, batch_size...  \n",
       "1  [model, peft, dataset, optim, seed, batch_size...  \n",
       "2  [model, peft, dataset, optim, seed, batch_size...  \n",
       "3  [model, peft, dataset, optim, seed, batch_size...  \n",
       "4  [model, peft, dataset, optim, seed, batch_size...  \n",
       "5  [model, peft, dataset, optim, seed, batch_size...  \n",
       "6  [model, peft, dataset, optim, seed, batch_size...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullfinetuned_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "finetune_mode = \"standard\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model = load_finetuned_model(model_name, dataset_name, finetune_mode, 1) # V1\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    if dataset_name in validataion_dataloaders:\n",
    "        val_loader = validataion_dataloaders[dataset_name]\n",
    "    else:\n",
    "        val_loader = load_validation_dataloaer(cfg)\n",
    "        validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    fullfinetuned_results[\"model\"].append(model_name)\n",
    "    fullfinetuned_results[\"dataset\"].append(dataset_name)\n",
    "    fullfinetuned_results[\"accuracy\"].append(acc)\n",
    "    fullfinetuned_results[\"config\"].append(cfg)\n",
    "\n",
    "    print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "fullfinetuned_results = pd.DataFrame(fullfinetuned_results)\n",
    "fullfinetuned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "fullfinetuned_results.to_csv(f\"results/{model_name}/fullfinetuned_results_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:56:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:56:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=205463;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=684865;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:56:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:56:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=472873;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=85561;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757684/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=4_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=3_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-cola/lora/version_0/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m3_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-cola/lora/version_0/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m4_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [00:17<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.6903163950143816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:56:45] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:56:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[18:56:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[18:56:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mnli/lora/version_0/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mnli/lora/version_0/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [03:20<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.6686704024452369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:00:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:00:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:00:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:00:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/lora/version_0/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/lora/version_0/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:08<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.7009803921568627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:00:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:00:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:00:23] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:00:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:00:24] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/lora/version_0/checkpoints                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:00:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/lora/version_0/checkpoints                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [16:14<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.7353203067029433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:16:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:16:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:16:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:16:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:16:43] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/lora/version_0/checkpoints                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:16:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/lora/version_0/checkpoints                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:07<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.8050541516245487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:16:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:16:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:16:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:16:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:16:54] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-sst2/lora/version_0/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:16:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-sst2/lora/version_0/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-sst2, accuracy: 0.9197247706422018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:17:08] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:17:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:17:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:17:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:17:12] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=5_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=6_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-stsb/lora/version_0/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:17:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m5_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-stsb/lora/version_0/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">5_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m5_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:28<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-stsb, accuracy: 0.14466666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.690316</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.668670</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.700980</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.735320</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.805054</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.919725</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.690316   \n",
       "1  flan-t5-base  glue-mnli  0.668670   \n",
       "2  flan-t5-base  glue-mrpc  0.700980   \n",
       "3  flan-t5-base   glue-qqp  0.735320   \n",
       "4  flan-t5-base   glue-rte  0.805054   \n",
       "5  flan-t5-base  glue-sst2  0.919725   \n",
       "6  flan-t5-base  glue-stsb  0.144667   \n",
       "\n",
       "                                              config  \n",
       "0  {'model': {'model': {'_target_': 'transformers...  \n",
       "1  {'model': {'model': {'_target_': 'transformers...  \n",
       "2  {'model': {'model': {'_target_': 'transformers...  \n",
       "3  {'model': {'model': {'_target_': 'transformers...  \n",
       "4  {'model': {'model': {'_target_': 'transformers...  \n",
       "5  {'model': {'model': {'_target_': 'transformers...  \n",
       "6  {'model': {'model': {'_target_': 'transformers...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "finetune_mode = \"lora\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model = load_finetuned_model(model_name, dataset_name, finetune_mode, 0)\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    if dataset_name in validataion_dataloaders:\n",
    "        val_loader = validataion_dataloaders[dataset_name]\n",
    "    else:\n",
    "        val_loader = load_validation_dataloaer(cfg)\n",
    "        validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    lora_results[\"model\"].append(model_name)\n",
    "    lora_results[\"dataset\"].append(dataset_name)\n",
    "    lora_results[\"accuracy\"].append(acc)\n",
    "    lora_results[\"config\"].append(str(cfg))\n",
    "\n",
    "    print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "lora_results = pd.DataFrame(lora_results)\n",
    "lora_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "lora_results.to_csv(f\"results/{model_name}/lora_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:15:13] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:15:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:15:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:15:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757684/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:15:17] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=4_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=3_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-cola/lora/version_1/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:15:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m3_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-cola/lora/version_1/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m4_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [00:17<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.6922339405560882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:15:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:15:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:15:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:15:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mnli/lora/version_1/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mnli/lora/version_1/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [03:28<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.7175751400916964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:19:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:19:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:19:10] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:19:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/lora/version_1/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/lora/version_1/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:09<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.7622549019607843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:19:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:19:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:19:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:19:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:19:23] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/lora/version_1/checkpoints                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:19:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/lora/version_1/checkpoints                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [16:00<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.7924066287410338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/lora/version_1/checkpoints                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/lora/version_1/checkpoints                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:07<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.8014440433212996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:38] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-sst2/lora/version_1/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-sst2/lora/version_1/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-sst2, accuracy: 0.9231651376146789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=5_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=6_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-stsb/lora/version_1/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m5_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-stsb/lora/version_1/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">5_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m5_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:35:56] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:35:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:28<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-stsb, accuracy: 0.14933333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.692234</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.717575</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.762255</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.792407</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.801444</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.923165</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.149333</td>\n",
       "      <td>{'model': {'model': {'_target_': 'transformers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.692234   \n",
       "1  flan-t5-base  glue-mnli  0.717575   \n",
       "2  flan-t5-base  glue-mrpc  0.762255   \n",
       "3  flan-t5-base   glue-qqp  0.792407   \n",
       "4  flan-t5-base   glue-rte  0.801444   \n",
       "5  flan-t5-base  glue-sst2  0.923165   \n",
       "6  flan-t5-base  glue-stsb  0.149333   \n",
       "\n",
       "                                              config  \n",
       "0  {'model': {'model': {'_target_': 'transformers...  \n",
       "1  {'model': {'model': {'_target_': 'transformers...  \n",
       "2  {'model': {'model': {'_target_': 'transformers...  \n",
       "3  {'model': {'model': {'_target_': 'transformers...  \n",
       "4  {'model': {'model': {'_target_': 'transformers...  \n",
       "5  {'model': {'model': {'_target_': 'transformers...  \n",
       "6  {'model': {'model': {'_target_': 'transformers...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "finetune_mode = \"lora\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model = load_finetuned_model(model_name, dataset_name, finetune_mode, 1)\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    if dataset_name in validataion_dataloaders:\n",
    "        val_loader = validataion_dataloaders[dataset_name]\n",
    "    else:\n",
    "        val_loader = load_validation_dataloaer(cfg)\n",
    "        validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    lora_results[\"model\"].append(model_name)\n",
    "    lora_results[\"dataset\"].append(dataset_name)\n",
    "    lora_results[\"accuracy\"].append(acc)\n",
    "    lora_results[\"config\"].append(str(cfg))\n",
    "\n",
    "    print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "lora_results = pd.DataFrame(lora_results)\n",
    "lora_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "lora_results.to_csv(f\"results/{model_name}/lora_results_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:10:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:10:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=375986;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=317788;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:10:10] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:10:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=485662;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=678469;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_379798/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:10:11] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=4_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=3_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-cola/lora/version_2/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:10:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=256787;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234053;file:///tmp/ipykernel_379798/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m3_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-cola/lora/version_2/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m4_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=935518;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=571858;file:///tmp/ipykernel_379798/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=31244;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=98246;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [00:17<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.6912751677852349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:10:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:10:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=27824;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=588508;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:10:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:10:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=571412;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439898;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:10:39] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mnli/lora/version_2/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:10:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_379798/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mnli/lora/version_2/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_379798/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [37:09<00:00,  7.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.7451859398879267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:47:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:47:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:47:57] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:47:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/lora/version_2/checkpoints                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_379798/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/lora/version_2/checkpoints                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_379798/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [04:00<00:00, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.7916666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:52:02] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:52:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:52:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:52:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:52:06] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/lora/version_2/checkpoints                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:52:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_379798/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/lora/version_2/checkpoints                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_379798/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:52:08] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[16:52:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=27824;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=588508;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [2:20:15<00:00,  6.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.8138263665594855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:12:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:12:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=571412;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=439898;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:12:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:12:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=848749;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=911527;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,462,592 || trainable%: 0.3560841867092814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:12:29] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/lora/version_2/checkpoints                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:12:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=288389;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_379798/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/lora/version_2/checkpoints                           \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=709570;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_379798/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_379798/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_379798/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_379798/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_379798/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Tue Aug  1 12:12:31 2023) since it couldn't be found locally at glue., or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:12:31] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Using the latest cached version of the module from                                 <a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1252</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">dac</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">be3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad</span> <span style=\"font-weight: bold\">(</span>last modified on    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         Tue Aug  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">12:12:31</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span><span style=\"font-weight: bold\">)</span> since it couldn't be found locally at glue., or remotely <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on the Hugging Face Hub.                                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:12:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Using the latest cached version of the module from                                 \u001b]8;id=529903;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py\u001b\\\u001b[2mload.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///data/users/tanganke/anaconda3/lib/python3.10/site-packages/datasets/load.py#1252\u001b\\\u001b[2m1252\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35m/data/users/tanganke/.cache/huggingface/modules/datasets_modules/datasets/glue/\u001b[0m\u001b[95mdac\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95mbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\u001b[0m \u001b[1m(\u001b[0mlast modified on    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         Tue Aug  \u001b[1;36m1\u001b[0m \u001b[1;92m12:12:31\u001b[0m \u001b[1;36m2023\u001b[0m\u001b[1m)\u001b[0m since it couldn't be found locally at glue., or remotely \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on the Hugging Face Hub.                                                           \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9569b9e3395f4e1d92466e416e08a3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.8050541516245487\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/users/tanganke/projects/task_arithmetic/peta/logs/flan-t5-base/glue-sst2/lora/version_2/config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m finetune_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlora\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m [\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mglue-cola\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mglue-mnli\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mglue-stsb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m ]:\n\u001b[0;32m---> 15\u001b[0m     model \u001b[39m=\u001b[39m load_finetuned_model(model_name, dataset_name, finetune_mode, version)\n\u001b[1;32m     16\u001b[0m     cfg, model, tokenizer \u001b[39m=\u001b[39m model[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m], model[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], model[\u001b[39m\"\u001b[39m\u001b[39mtokenizer\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m validataion_dataloaders:\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mload_finetuned_model\u001b[0;34m(model, dataset, finetune_mode, version)\u001b[0m\n\u001b[1;32m      7\u001b[0m log_dir: Path \u001b[39m=\u001b[39m (\n\u001b[1;32m      8\u001b[0m     Path(\u001b[39m\"\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m/\u001b[39m model \u001b[39m/\u001b[39m dataset \u001b[39m/\u001b[39m finetune_mode \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mversion_\u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m config_path \u001b[39m=\u001b[39m log_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconfig.yaml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m cfg: DictConfig \u001b[39m=\u001b[39m OmegaConf\u001b[39m.\u001b[39;49mload(config_path)\n\u001b[1;32m     13\u001b[0m \u001b[39m# load model from config\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mwith\u001b[39;00m TitledLog(\u001b[39m\"\u001b[39m\u001b[39mload pretrained model and tokenizer\u001b[39m\u001b[39m\"\u001b[39m, log_fn\u001b[39m=\u001b[39mlog\u001b[39m.\u001b[39minfo):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/omegaconf/omegaconf.py:189\u001b[0m, in \u001b[0;36mOmegaConf.load\u001b[0;34m(file_)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_yaml_loader\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(file_, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPath)):\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mabspath(file_), \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    190\u001b[0m         obj \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39mload(f, Loader\u001b[39m=\u001b[39mget_yaml_loader())\n\u001b[1;32m    191\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mgetattr\u001b[39m(file_, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/users/tanganke/projects/task_arithmetic/peta/logs/flan-t5-base/glue-sst2/lora/version_2/config.yaml'"
     ]
    }
   ],
   "source": [
    "for version in range(2, 10):\n",
    "    lora_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "    model_name = \"flan-t5-base\"\n",
    "    finetune_mode = \"lora\"\n",
    "    for dataset_name in [\n",
    "        \"glue-cola\",\n",
    "        \"glue-mnli\",\n",
    "        \"glue-mrpc\",\n",
    "        \"glue-qqp\",\n",
    "        \"glue-rte\",\n",
    "        \"glue-sst2\",\n",
    "        \"glue-stsb\",\n",
    "    ]:\n",
    "        model = load_finetuned_model(model_name, dataset_name, finetune_mode, version)\n",
    "        cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "        if dataset_name in validataion_dataloaders:\n",
    "            val_loader = validataion_dataloaders[dataset_name]\n",
    "        else:\n",
    "            val_loader = load_validation_dataloaer(cfg)\n",
    "            validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "        model = fabric.setup_module(model)\n",
    "        val_loader = fabric.setup_dataloaders(val_loader)\n",
    "        acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "        lora_results[\"model\"].append(model_name)\n",
    "        lora_results[\"dataset\"].append(dataset_name)\n",
    "        lora_results[\"accuracy\"].append(acc)\n",
    "        lora_results[\"config\"].append(str(cfg))\n",
    "\n",
    "        print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "    lora_results = pd.DataFrame(lora_results)\n",
    "    lora_results\n",
    "\n",
    "    os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "    lora_results.to_csv(f\"results/{model_name}/lora_results_v{version}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L_LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:29:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:29:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=638551;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=208573;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:29:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:29:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=565579;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=999816;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757684/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:29:52] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=4_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=3_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-cola/l_lora/version_0/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:29:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m3_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-cola/l_lora/version_0/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m4_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [00:32<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.48609779482262705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:30:28] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mnli/l_lora/version_0/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:30:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mnli/l_lora/version_0/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [06:25<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.00010188487009679063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:36:57] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:36:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/l_lora/version_0/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/l_lora/version_0/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:19<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:37:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:37:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[22:37:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[22:37:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/l_lora/version_0/checkpoints                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/l_lora/version_0/checkpoints                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [28:43<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:07] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/l_lora/version_0/checkpoints                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/l_lora/version_0/checkpoints                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-sst2/l_lora/version_0/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-sst2/l_lora/version_0/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-sst2, accuracy: 0.8761467889908257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:45] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[23:06:49] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=5_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=6_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-stsb/l_lora/version_0/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[23:06:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m5_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-stsb/l_lora/version_0/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">5_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m5_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:42<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-stsb, accuracy: 0.0006666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.486098</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.876147</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.486098   \n",
       "1  flan-t5-base  glue-mnli  0.000102   \n",
       "2  flan-t5-base  glue-mrpc  0.000000   \n",
       "3  flan-t5-base   glue-qqp  0.000000   \n",
       "4  flan-t5-base   glue-rte  0.000000   \n",
       "5  flan-t5-base  glue-sst2  0.876147   \n",
       "6  flan-t5-base  glue-stsb  0.000667   \n",
       "\n",
       "                                              config  \n",
       "0  [model, peft, dataset, optim, seed, batch_size...  \n",
       "1  [model, peft, dataset, optim, seed, batch_size...  \n",
       "2  [model, peft, dataset, optim, seed, batch_size...  \n",
       "3  [model, peft, dataset, optim, seed, batch_size...  \n",
       "4  [model, peft, dataset, optim, seed, batch_size...  \n",
       "5  [model, peft, dataset, optim, seed, batch_size...  \n",
       "6  [model, peft, dataset, optim, seed, batch_size...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 0\n",
    "l_lora_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "finetune_mode = \"l_lora\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model = load_finetuned_model(model_name, dataset_name, finetune_mode, 0)\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    if dataset_name in validataion_dataloaders:\n",
    "        val_loader = validataion_dataloaders[dataset_name]\n",
    "    else:\n",
    "        val_loader = load_validation_dataloaer(cfg)\n",
    "        validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    l_lora_results[\"model\"].append(model_name)\n",
    "    l_lora_results[\"dataset\"].append(dataset_name)\n",
    "    l_lora_results[\"accuracy\"].append(acc)\n",
    "    l_lora_results[\"config\"].append(cfg)\n",
    "\n",
    "    print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "l_lora_results = pd.DataFrame(l_lora_results)\n",
    "l_lora_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.486098</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.876147</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.486098   \n",
       "1  flan-t5-base  glue-mnli  0.000102   \n",
       "2  flan-t5-base  glue-mrpc  0.000000   \n",
       "3  flan-t5-base   glue-qqp  0.000000   \n",
       "4  flan-t5-base   glue-rte  0.000000   \n",
       "5  flan-t5-base  glue-sst2  0.876147   \n",
       "6  flan-t5-base  glue-stsb  0.000667   \n",
       "\n",
       "                                              config  \n",
       "0  [model, peft, dataset, optim, seed, batch_size...  \n",
       "1  [model, peft, dataset, optim, seed, batch_size...  \n",
       "2  [model, peft, dataset, optim, seed, batch_size...  \n",
       "3  [model, peft, dataset, optim, seed, batch_size...  \n",
       "4  [model, peft, dataset, optim, seed, batch_size...  \n",
       "5  [model, peft, dataset, optim, seed, batch_size...  \n",
       "6  [model, peft, dataset, optim, seed, batch_size...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_lora_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "l_lora_results.to_csv(f\"results/{model_name}/l_lora_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:41:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:41:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:41:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:41:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1757684/993648505.py:31: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  log.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:41:55] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=4_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=3_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-cola/l_lora/version_1/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:41:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m4_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m3_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-cola/l_lora/version_1/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">4_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m4_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]/data/users/tanganke/anaconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 33/33 [00:23<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-cola, accuracy: 0.6883988494726749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:42:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:42:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:42:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:42:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:42:23] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mnli/l_lora/version_1/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:42:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mnli/l_lora/version_1/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 307/307 [05:41<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mnli, accuracy: 0.28863983698420786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:48:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:48:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:48:08] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:48:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:48:09] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=8_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=9_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-mrpc/l_lora/version_1/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:48:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m9_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-mrpc/l_lora/version_1/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">8_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m8_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 13/13 [00:10<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-mrpc, accuracy: 0.6838235294117647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:48:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:48:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:48:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:48:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[20:48:23] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-qqp/l_lora/version_1/checkpoints                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[20:48:23]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-qqp/l_lora/version_1/checkpoints                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 1264/1264 [25:27<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-qqp, accuracy: 0.47140737076428396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:13:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:13:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:13:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:13:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=12_step=2000.pth'</span>,       <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=13_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-rte/l_lora/version_1/checkpoints                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m12_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,       \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m13_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                      \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-rte/l_lora/version_1/checkpoints                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">12_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                     <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m12_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                     \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 9/9 [00:10<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-rte, accuracy: 0.4729241877256318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:14:06] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:14:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:14:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:14:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=0_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=1_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-sst2/l_lora/version_1/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-sst2/l_lora/version_1/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">0_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m0_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 28/28 [00:19<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-sst2, accuracy: 0.9174311926605505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:14:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> =======load pretrained model and <span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span>========                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:14:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m =======load pretrained model and \u001b[33mtokenizer\u001b[0m========                              \u001b]8;id=529903;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[21:14:32] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> set peft seed to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>                                                          <a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">finetune_lm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[21:14:32]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m set peft seed to \u001b[1;36m42\u001b[0m                                                          \u001b]8;id=681453;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py\u001b\\\u001b[2mfinetune_lm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///data/users/tanganke/projects/task_arithmetic/peta/finetune_lm.py#121\u001b\\\u001b[2m121\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 291,814,656 || trainable%: 0.30318422389312755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> multiple checkpoints found, found checkpoints: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'epoch=5_step=2000.pth'</span>,        <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'epoch=6_step=2000.pth'</span><span style=\"font-weight: bold\">]</span>, checkpoint dir:                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         logs/flan-t5-base/glue-stsb/l_lora/version_1/checkpoints                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m multiple checkpoints found, found checkpoints: \u001b[1m[\u001b[0m\u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m5_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m,        \u001b]8;id=288389;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///tmp/ipykernel_1757684/993648505.py#31\u001b\\\u001b[2m31\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m6_step\u001b[0m\u001b[32m=2000.pth'\u001b[0m\u001b[1m]\u001b[0m, checkpoint dir:                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         logs/flan-t5-base/glue-stsb/l_lora/version_1/checkpoints                        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> load checkpoint from <span style=\"color: #808000; text-decoration-color: #808000\">epoch</span>=<span style=\"color: #800080; text-decoration-color: #800080\">5_step</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000.</span>pth                                      <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m load checkpoint from \u001b[33mepoch\u001b[0m=\u001b[35m5_step\u001b[0m=\u001b[1;36m2000.\u001b[0mpth                                      \u001b]8;id=709570;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///tmp/ipykernel_1757684/993648505.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ==================================================                              <a href=\"file:///tmp/ipykernel_1757684/993648505.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">993648505.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_1757684/993648505.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ==================================================                              \u001b]8;id=442417;file:///tmp/ipykernel_1757684/993648505.py\u001b\\\u001b[2m993648505.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///tmp/ipykernel_1757684/993648505.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "100%|██████████| 47/47 [00:40<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: flan-t5-base, dataset: glue-stsb, accuracy: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-cola</td>\n",
       "      <td>0.688399</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mnli</td>\n",
       "      <td>0.288640</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-mrpc</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-qqp</td>\n",
       "      <td>0.471407</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-rte</td>\n",
       "      <td>0.472924</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-sst2</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>glue-stsb</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>[model, peft, dataset, optim, seed, batch_size...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model    dataset  accuracy  \\\n",
       "0  flan-t5-base  glue-cola  0.688399   \n",
       "1  flan-t5-base  glue-mnli  0.288640   \n",
       "2  flan-t5-base  glue-mrpc  0.683824   \n",
       "3  flan-t5-base   glue-qqp  0.471407   \n",
       "4  flan-t5-base   glue-rte  0.472924   \n",
       "5  flan-t5-base  glue-sst2  0.917431   \n",
       "6  flan-t5-base  glue-stsb  0.030000   \n",
       "\n",
       "                                              config  \n",
       "0  [model, peft, dataset, optim, seed, batch_size...  \n",
       "1  [model, peft, dataset, optim, seed, batch_size...  \n",
       "2  [model, peft, dataset, optim, seed, batch_size...  \n",
       "3  [model, peft, dataset, optim, seed, batch_size...  \n",
       "4  [model, peft, dataset, optim, seed, batch_size...  \n",
       "5  [model, peft, dataset, optim, seed, batch_size...  \n",
       "6  [model, peft, dataset, optim, seed, batch_size...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 1\n",
    "l_lora_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "model_name = \"flan-t5-base\"\n",
    "finetune_mode = \"l_lora\"\n",
    "for dataset_name in [\n",
    "    \"glue-cola\",\n",
    "    \"glue-mnli\",\n",
    "    \"glue-mrpc\",\n",
    "    \"glue-qqp\",\n",
    "    \"glue-rte\",\n",
    "    \"glue-sst2\",\n",
    "    \"glue-stsb\",\n",
    "]:\n",
    "    model = load_finetuned_model(model_name, dataset_name, finetune_mode, 1) # version 1\n",
    "    cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "    if dataset_name in validataion_dataloaders:\n",
    "        val_loader = validataion_dataloaders[dataset_name]\n",
    "    else:\n",
    "        val_loader = load_validation_dataloaer(cfg)\n",
    "        validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "    model = fabric.setup_module(model)\n",
    "    val_loader = fabric.setup_dataloaders(val_loader)\n",
    "    acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "    l_lora_results[\"model\"].append(model_name)\n",
    "    l_lora_results[\"dataset\"].append(dataset_name)\n",
    "    l_lora_results[\"accuracy\"].append(acc)\n",
    "    l_lora_results[\"config\"].append(cfg)\n",
    "\n",
    "    print(\"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc))\n",
    "\n",
    "l_lora_results = pd.DataFrame(l_lora_results)\n",
    "l_lora_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "l_lora_results.to_csv(f\"results/{model_name}/l_lora_results_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in range(2, 12):\n",
    "    l_lora_results = {\"model\": [], \"dataset\": [], \"accuracy\": [], \"config\": []}\n",
    "\n",
    "    model_name = \"flan-t5-base\"\n",
    "    finetune_mode = \"l_lora\"\n",
    "    for dataset_name in [\n",
    "        \"glue-cola\",\n",
    "        \"glue-mnli\",\n",
    "        \"glue-mrpc\",\n",
    "        \"glue-qqp\",\n",
    "        \"glue-rte\",\n",
    "        \"glue-sst2\",\n",
    "        \"glue-stsb\",\n",
    "    ]:\n",
    "        model = load_finetuned_model(\n",
    "            model_name, dataset_name, finetune_mode, version\n",
    "        )  # version 1\n",
    "        cfg, model, tokenizer = model[\"config\"], model[\"model\"], model[\"tokenizer\"]\n",
    "\n",
    "        if dataset_name in validataion_dataloaders:\n",
    "            val_loader = validataion_dataloaders[dataset_name]\n",
    "        else:\n",
    "            val_loader = load_validation_dataloaer(cfg)\n",
    "            validataion_dataloaders[dataset_name] = val_loader\n",
    "\n",
    "        model = fabric.setup_module(model)\n",
    "        val_loader = fabric.setup_dataloaders(val_loader)\n",
    "        acc = evaluate_accuracy(model, val_loader, tokenizer)\n",
    "\n",
    "        l_lora_results[\"model\"].append(model_name)\n",
    "        l_lora_results[\"dataset\"].append(dataset_name)\n",
    "        l_lora_results[\"accuracy\"].append(acc)\n",
    "        l_lora_results[\"config\"].append(cfg)\n",
    "\n",
    "        print(\n",
    "            \"model: {}, dataset: {}, accuracy: {}\".format(model_name, dataset_name, acc)\n",
    "        )\n",
    "\n",
    "    l_lora_results = pd.DataFrame(l_lora_results)\n",
    "    l_lora_results\n",
    "\n",
    "    os.makedirs(f\"results/{model_name}\", exist_ok=True)\n",
    "    l_lora_results.to_csv(f\"results/{model_name}/l_lora_results_v{version}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
